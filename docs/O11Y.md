# ⚡ Agent Network Observability

**Agents debugging agents. High-cardinality structured logs as first-class citizens.**

> "Events capture WHAT happened. Context graphs explain WHY."
> — swarm-tools philosophy

## Design Principles

### 1. Agent-First, Human-Second

The CLI is optimized for **agents querying logs**, not humans browsing dashboards. Every command:

- Outputs structured JSON by default (human-friendly formatting opt-in)
- Supports jq-style filtering on any field
- Handles batch operations (millions of events)
- Returns machine-parseable exit codes
- Works across network boundaries (aggregate from multiple agents)

```bash
# Agent querying its own logs
zap logs --since 5m --type tool_call | jq '.[] | select(.latency_ms > 1000)'

# Agent analyzing another agent's public logs
zap logs --agent did:cf:bob --public --since 1h --json

# Coordinator aggregating network state
zap network --metric throughput --window 1h --format prometheus
```

### 2. High Cardinality by Default

Every event captures rich context. No more "what fields should we log?":

```typescript
interface AgentEvent {
  // Identity
  id: string                    // Unique event ID (ULID)
  agent_did: string             // did:cf:<durable-object-id>
  session_id: string            // Session/conversation ID
  
  // Timing
  timestamp: string             // ISO-8601
  duration_ms?: number          // For operations with latency
  
  // Event type
  event_type: EventType         // tool_call, memory_access, message_sent, etc.
  outcome: 'success' | 'error' | 'timeout' | 'skipped'
  
  // Context (varies by event type)
  context: Record<string, unknown>
  
  // Trace correlation
  trace_id?: string             // OpenTelemetry-style trace ID
  parent_span_id?: string       // For nested operations
  span_id: string               // This event's span
  
  // Reasoning trace
  reasoning?: {
    decision: string            // What was decided
    rationale: string           // WHY (natural language)
    alternatives?: string[]     // What was considered but rejected
    confidence?: number         // 0-1
  }
  
  // Error context (when outcome = 'error')
  error?: {
    code: string
    message: string
    stack?: string
    retryable: boolean
    context: Record<string, unknown>
  }
}
```

### 3. Decentralized but Aggregatable

Each agent owns their logs. But the network can aggregate:

```
┌─────────────────────────────────────────────────────────────────┐
│                         AGENT LOGS                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   did:cf:alice           did:cf:bob           did:cf:charlie    │
│   ┌──────────┐           ┌──────────┐         ┌──────────┐      │
│   │ Local    │           │ Local    │         │ Local    │      │
│   │ Events   │           │ Events   │         │ Events   │      │
│   │ (D1)     │           │ (D1)     │         │ (D1)     │      │
│   └────┬─────┘           └────┬─────┘         └────┬─────┘      │
│        │                      │                    │             │
│        │     Selective export (public events)      │             │
│        └──────────────────────┼────────────────────┘             │
│                               ▼                                  │
│                     ┌─────────────────┐                         │
│                     │  Network Index  │                         │
│                     │  (Coordinator)  │                         │
│                     │                 │                         │
│                     │ • Public events │                         │
│                     │ • Health metrics│                         │
│                     │ • Aggregate     │                         │
│                     │   analytics     │                         │
│                     └─────────────────┘                         │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**Privacy levels for events:**
- `private` (default) — Only the agent can query
- `shared` — Specific agents can query (encrypted for recipients)
- `public` — Visible in network firehose, indexed for all

### 4. AT Protocol Native

Logs are AT Protocol records. Queryable, federable, verifiable:

```typescript
// Lexicon: agent.observability.event
const EventLexicon = {
  lexicon: 1,
  id: 'agent.observability.event',
  defs: {
    main: {
      type: 'record',
      key: 'tid',
      record: {
        type: 'object',
        required: ['eventType', 'timestamp', 'outcome'],
        properties: {
          eventType: { type: 'string' },
          timestamp: { type: 'string', format: 'datetime' },
          outcome: { type: 'string', enum: ['success', 'error', 'timeout', 'skipped'] },
          durationMs: { type: 'integer' },
          context: { type: 'unknown' },
          reasoning: {
            type: 'object',
            properties: {
              decision: { type: 'string' },
              rationale: { type: 'string' },
              alternatives: { type: 'array', items: { type: 'string' } },
              confidence: { type: 'number' }
            }
          }
        }
      }
    }
  }
}
```

## Event Types

### Core Events

| Event Type | Description | Key Context Fields |
|------------|-------------|-------------------|
| `agent.started` | Agent DO initialized | `version`, `config` |
| `agent.prompt` | Agent received prompt | `prompt_hash`, `token_count` |
| `agent.response` | Agent completed response | `token_count`, `model`, `latency_ms` |
| `agent.tool_call` | Tool invoked | `tool_name`, `params`, `result_summary` |
| `agent.tool_error` | Tool failed | `tool_name`, `error`, `retryable` |
| `memory.store` | Memory stored | `collection`, `record_id`, `privacy` |
| `memory.search` | Memory queried | `query_hash`, `results_count`, `latency_ms` |
| `memory.share` | Memory shared | `record_id`, `recipient`, `privacy` |
| `comms.message_sent` | Message to other agent | `recipient`, `message_type`, `encrypted` |
| `comms.message_received` | Message from other agent | `sender`, `message_type`, `decrypted` |
| `comms.task_delegated` | Task sent to worker | `worker`, `task_type`, `deadline` |
| `comms.task_completed` | Delegated task done | `task_id`, `worker`, `outcome` |
| `network.firehose` | Processed firehose event | `source`, `event_type`, `matched_filter` |
| `error.unhandled` | Unhandled error | `error`, `stack`, `recovery_action` |

### Decision Traces

Capture WHY decisions were made (from swarm-tools pattern):

```typescript
interface DecisionTrace extends AgentEvent {
  event_type: 'decision'
  context: {
    decision_type: 'tool_selection' | 'memory_retrieval' | 'task_delegation' | 'response_generation'
    inputs_gathered: string[]     // What context was consulted
    alternatives: {
      option: string
      score?: number
      rejected_reason?: string
    }[]
    selected: string
    confidence: number
    rationale: string             // Natural language WHY
  }
}
```

Example:
```json
{
  "id": "01HXQ...",
  "event_type": "decision",
  "context": {
    "decision_type": "tool_selection",
    "inputs_gathered": [
      "user_prompt: 'save this for later'",
      "recent_memory: 3 items about user preferences",
      "available_tools: [remember, recall, share]"
    ],
    "alternatives": [
      { "option": "recall", "rejected_reason": "prompt asks to SAVE, not retrieve" },
      { "option": "share", "rejected_reason": "no recipient specified" }
    ],
    "selected": "remember",
    "confidence": 0.92,
    "rationale": "User explicitly requested saving. 'remember' tool stores to encrypted memory."
  }
}
```

## CLI Reference: `zap`

The observability CLI. Named because it's fast ⚡ and zaps through logs.

### Log Viewing

```bash
# Recent logs (last 50)
zap logs

# JSON output (default for agents, opt-in for humans)
zap logs --json

# Human-friendly output
zap logs --pretty

# Filter by time
zap logs --since 5m           # Last 5 minutes
zap logs --since 2h           # Last 2 hours
zap logs --since "2025-01-01" # Since date
zap logs --window 1h          # Sliding window

# Filter by event type
zap logs --type tool_call
zap logs --type decision,memory.store

# Filter by outcome
zap logs --outcome error
zap logs --outcome success --type tool_call

# Filter by agent (self is default)
zap logs --agent did:cf:alice

# Filter by session
zap logs --session sess-123

# Complex filters (jq-style)
zap logs --filter '.latency_ms > 1000'
zap logs --filter '.context.tool_name == "remember"'
zap logs --filter '.reasoning.confidence < 0.5'

# Watch mode (tail)
zap logs --watch
zap logs --watch --type error
```

### Analytics (Query Presets)

```bash
# Built-in queries (agent-friendly output)
zap query --preset slow_tools          # Tools with p99 > 1s
zap query --preset error_rate          # Error rate by type
zap query --preset decision_confidence # Low-confidence decisions
zap query --preset memory_hotspots     # Most accessed memories
zap query --preset message_latency     # Inter-agent messaging p50/p99
zap query --preset tool_usage          # Tool call distribution

# Custom SQL (for power users)
zap query --sql "SELECT event_type, COUNT(*) FROM events WHERE outcome='error' GROUP BY event_type"

# Output formats
zap query --preset error_rate --format json
zap query --preset error_rate --format csv
zap query --preset error_rate --format prometheus  # For scraping
```

### Decision Trace Analysis

```bash
# View reasoning for specific event
zap trace <event-id>

# Find decisions with low confidence
zap traces --confidence-lt 0.5

# Replay decision sequence for session
zap replay --session sess-123 --type decision

# Compare decision patterns across agents
zap traces --agent did:cf:alice,did:cf:bob --type tool_selection --diff
```

### Network Observability

```bash
# Network-wide health
zap network health

# Message flow graph
zap network graph --window 1h

# Agent status
zap network agents
zap network agents --status active

# Throughput metrics
zap network metrics --metric throughput --window 5m
zap network metrics --metric error_rate --window 1h

# Export for external systems
zap network export --format otlp --output traces.otlp
zap network export --format prometheus --output metrics.txt
```

### Self-Diagnosis

```bash
# Agent health check
zap doctor

# Storage usage
zap storage
zap storage --collection agent.observability.event

# Index health
zap indexes

# Performance profile
zap profile --duration 60s
```

## Storage Architecture

### Per-Agent Event Store (D1)

Each agent has their own events table:

```sql
CREATE TABLE events (
  id TEXT PRIMARY KEY,           -- ULID
  event_type TEXT NOT NULL,
  outcome TEXT NOT NULL,
  timestamp TEXT NOT NULL,
  duration_ms INTEGER,
  session_id TEXT,
  trace_id TEXT,
  span_id TEXT,
  parent_span_id TEXT,
  context TEXT,                  -- JSON
  reasoning TEXT,                -- JSON (optional)
  error TEXT,                    -- JSON (optional)
  privacy TEXT DEFAULT 'private',
  created_at TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_events_type ON events(event_type);
CREATE INDEX idx_events_outcome ON events(outcome);
CREATE INDEX idx_events_timestamp ON events(timestamp);
CREATE INDEX idx_events_session ON events(session_id);
CREATE INDEX idx_events_trace ON events(trace_id);
CREATE INDEX idx_events_privacy ON events(privacy);
```

### Network Index (Coordinator D1)

Aggregate public events for network-wide queries:

```sql
CREATE TABLE network_events (
  id TEXT PRIMARY KEY,
  agent_did TEXT NOT NULL,
  event_type TEXT NOT NULL,
  outcome TEXT NOT NULL,
  timestamp TEXT NOT NULL,
  duration_ms INTEGER,
  summary TEXT,                  -- Stripped-down context (no secrets)
  FOREIGN KEY (agent_did) REFERENCES agents(did)
);

CREATE INDEX idx_network_events_agent ON network_events(agent_did);
CREATE INDEX idx_network_events_type ON network_events(event_type);
CREATE INDEX idx_network_events_timestamp ON network_events(timestamp);
```

### Retention Policy

Events are compacted over time:

| Age | Retention |
|-----|-----------|
| < 24h | Full detail |
| 1-7 days | Summarized (reasoning collapsed) |
| 7-30 days | Aggregated (hourly buckets) |
| > 30 days | Metrics only (counts, p50/p99) |

Compaction runs via Cloudflare Queues on a schedule.

## Integration Points

### OpenTelemetry Export

```typescript
// Export to OTLP-compatible backend
const exporter = new OTLPTraceExporter({
  url: process.env.OTLP_ENDPOINT,
  headers: { 'Authorization': `Bearer ${process.env.OTLP_TOKEN}` }
})

// Agent events are spans
eventStore.on('event', (event) => {
  const span = {
    traceId: event.trace_id,
    spanId: event.span_id,
    parentSpanId: event.parent_span_id,
    name: event.event_type,
    kind: 'INTERNAL',
    startTime: event.timestamp,
    endTime: event.duration_ms 
      ? new Date(new Date(event.timestamp).getTime() + event.duration_ms)
      : event.timestamp,
    attributes: flattenContext(event.context),
    status: event.outcome === 'error' 
      ? { code: 'ERROR', message: event.error?.message }
      : { code: 'OK' }
  }
  exporter.export([span])
})
```

### Prometheus Metrics

```bash
# Expose metrics endpoint
zap serve --port 9090

# Metrics available at /metrics
curl http://localhost:9090/metrics

# Example output
# TYPE agent_events_total counter
agent_events_total{event_type="tool_call",outcome="success"} 1234
agent_events_total{event_type="tool_call",outcome="error"} 56
agent_events_total{event_type="memory.store",outcome="success"} 789

# TYPE agent_tool_latency_ms histogram
agent_tool_latency_ms_bucket{tool="remember",le="100"} 500
agent_tool_latency_ms_bucket{tool="remember",le="500"} 800
agent_tool_latency_ms_bucket{tool="remember",le="1000"} 900
```

### Workers Analytics (Native)

Cloudflare Workers Analytics Engine for real-time:

```typescript
// Write to Analytics Engine
env.ANALYTICS.writeDataPoint({
  blobs: [event.event_type, event.outcome, event.agent_did],
  doubles: [event.duration_ms ?? 0],
  indexes: [event.session_id]
})

// Query via GraphQL
const query = `
  query {
    viewer {
      accounts(filter: { accountTag: $accountTag }) {
        agentEvents(
          filter: { datetime_gt: $since }
          limit: 1000
        ) {
          sum { count }
          dimensions { eventType outcome }
          avg { durationMs }
        }
      }
    }
  }
`
```

## Implementation Phases

### Phase 1: Local Logging (Week 1-2 overlap)

- [ ] Event schema + TypeScript types
- [ ] D1 event store per agent
- [ ] Core event emission in Pi agent wrapper
- [ ] `zap logs` CLI with basic filters
- [ ] `zap logs --watch` for tailing

### Phase 2: Query + Analytics (Week 2)

- [ ] Query presets (slow_tools, error_rate, etc.)
- [ ] Custom SQL queries
- [ ] Decision trace capture + viewing
- [ ] `zap trace` and `zap traces` commands
- [ ] JSON + CSV + human-pretty output

### Phase 3: Network Aggregation (Week 3)

- [ ] Coordinator event index
- [ ] Public event publishing
- [ ] `zap network` commands
- [ ] Cross-agent trace correlation
- [ ] Network health dashboard

### Phase 4: Export + Integration (Week 4)

- [ ] OTLP exporter
- [ ] Prometheus metrics endpoint
- [ ] Workers Analytics integration
- [ ] Retention + compaction
- [ ] `zap doctor` health checks

## References

- **swarm-tools observability:** Query presets, decision traces, replay, export patterns
- **OpenTelemetry:** Trace/span model, OTLP protocol
- **Cloudflare Analytics Engine:** Real-time metrics at edge scale
- **Pino logging:** Structured JSON, fast file writes
